# -*- coding: utf-8 -*-
"""Agriculture_Pytorch

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H1x1UcSudWmLBUz-bZ3tynPXup6Br9Yy
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

import torch, torchvision
from torchvision.transforms import transforms
from torch.autograd import Variable
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
import cv2

# %matplotlib inline

from google.colab import files
uploaded = files.upload()

import io
df_test = pd.read_csv(io.BytesIO(uploaded['Test_agri.csv']))
df_train = pd.read_csv(io.BytesIO(uploaded['train_agri.csv']))

df_train.head()

df_train.isnull().sum()

df_train['Number_Weeks_Used'].value_counts()

df_train['Number_Weeks_Used'] = df_train['Number_Weeks_Used'].fillna(df_train['Number_Weeks_Used'].median())

df_train['Number_Weeks_Used'].isnull().sum()

encoder = LabelEncoder()

df_train['ID'] = encoder.fit_transform(df_train['ID'])

df_test.isnull().sum()

df_test['Number_Weeks_Used'] = df_test['Number_Weeks_Used'].fillna(df_test['Number_Weeks_Used'].median())

df_test.isnull().sum()

df_test['ID'] = encoder.fit_transform(df_test['ID'])

df_train.head()

df_test.head()

y = np.array(df_train['Crop_Damage'])

y

X = np.array(df_train.iloc[:, df_train.columns != 'Crop_Damage'])

X

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.35)

X_train.shape

X_train

y_train.shape

from torch.utils.data import DataLoader

batch_size = 100
train_dataloader = DataLoader(X_train, batch_size, shuffle = True)

for data in train_dataloader:
  print(data)
  break



from torch.autograd import Variable

X_train = Variable(torch.from_numpy(X_train))
X_test = Variable(torch.from_numpy(X_test))
y_train = Variable(torch.from_numpy(y_train))
y_test = Variable(torch.from_numpy(y_test))

X_train

y_train = y_train.view(y_train.shape[0], 1)
y_test = y_test.view(y_test.shape[0], 1)

y_train

class Model(torch.nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.l1 = torch.nn.Linear(9,32)
        self.l2 = torch.nn.Linear(32,64)
        self.l3 = torch.nn.Linear(64,128)
        self.l4 = torch.nn.Linear(128,64)
        self.l5 = torch.nn.Linear(64,1)
        self.drop = torch.nn.Dropout(0.25)
        
    def forward(self, x):
        x = F.relu(self.l1(x)) 
        x = F.relu(self.l2(x))
        x = F.relu(self.l3(x))
        x = F.relu(self.l4(x))
        x = F.dropout(x)
        
        return torch.softmax(self.l5(x), dim = 0)
    
model = Model()
print(model)

optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)

criterion = nn.BCELoss()


for epoch in range(3):
  y_pred = model(X_train.float())
  loss = criterion(y_pred, y_train.float())

  # zero gradients
  optimizer.zero_grad()

  # backward pass
  loss.backward()

  # updated for weights 
  optimizer.step()

print(loss)

correct = 0
total = 0

with torch.no_grad():
  output = model(X_train.float())
  for idx, i in enumerate(output):
    if torch.argmax(i) == y[idx]:

      correct += 1
    total += 1

print("Accuracy : ", correct/total * 100)

X_df_test = np.array(df_test)

X_df_test = Variable(torch.from_numpy(X_df_test))

y_pred = model(X_df_test.float())

y_pred.shape

